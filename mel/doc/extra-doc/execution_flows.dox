/**
\page execution_flows Work flows
- [Introduction](#introduction)
- [Conditions](#conditions)
- [Launching flows](#launching_flows)
- [Loops](#loops)
- [Flow chart example](#flow_chart)

###Introduction {#introduction}
It's possible to create independent work flows to reuse then or apply them at functions as \ref ::mel::execution::condition "condition". A *flow* could be defined as
a callable with signature ```ExFuture<...> flow( ExFuture<...> )```, meaning that it can substitute a chain of job. With the help of *generic lambdas* this callable will be
defined as ```[](auto input)->auto```.

The lambda or callable used as a flow will receive an \ref ::mel::execution::ExFuture "ExFuture" which serves as the input of any other *execution* function.
Let's start with a simple example, defining two flows:
\code
template <class ExecutorType> void _sampleFlows1(ExecutorType ex)
{	
	auto th = ThreadRunnable::create();

	//create a flow. input parameter is an ExFuture depending on given executor
	auto flow1 = [](auto input)
	{
		return input | execution::next(
			[](const string& str)
			{
				return str+" Dani";
			}
		);
	};

	th->fireAndForget([ex,flow1] () mutable
	{
        auto res = mel::tasking::waitForFutureMThread<::mel::core::WaitErrorNoException>(
				execution::launch(ex,[]()
				{
					return "Hello"s;
				}
			)
			| flow1
			| execution::next([](const string& str)
				{
					return 	str + " Barrientos";
				}
			)
			| 
			[](auto input)
			{
				return input | execution::next([](const string& str)
					{
						return str + ". Bye!!";
					}
				);
			}
		);
		if ( res.isValid())
		{
			text::info("Result = {}",res.value());
		}else
		{
			try
			{
				std::rethrow_exception(res.error());				
			}
			catch(...)
			{
				::text::error("Some error occured!!");
			}
		}
		
	},0,::tasking::Runnable::killFalse);
}
\endcode
Output will be:
\verbatim
Result = Hello Dani Barrientos. Bye!!
\endverbatim
### Conditions {#conditions}
Besides creating flows for reusability, one important use is for \ref ::mel::execution::condition "conditions", which are the equivalent to a normal *switch*, 
such that a flow is selected based on the previous result in the chain. In the next example a flow is chosen, between two, according to a random number. Both flows 
are written as lambas local to the function, but any other callbable could be used or lambdas written inline in the code, it's shown this way for clarity.

\code{.cpp}
template <class ExecutorType> void _sampleFlowsCondition(ExecutorType ex)
{	
	auto th = ThreadRunnable::create();

	//create a flow. input paramter is an ExFuture depending on given executor
	auto flow0 = [](/*execution::ExFuture<ExecutorType,string> */auto input)
	{
		return input | execution::next(
			[](int val)
			{
				return "Flow0";
			}
		);
	};
	auto flow1 = [](auto input)
	{
		return input | execution::next(
			[](int val)
			{
				return "Flow1";
			}
		);
	};

	th->fireAndForget([ex,flow0,flow1] () mutable
	{
		srand(time(NULL));
        auto res = mel::tasking::waitForFutureMThread<::mel::core::WaitErrorNoException>(
				execution::launch(ex,[]()
				{
					return rand()%10;
				}
			)
			| execution::condition(
				[](int val)
				{
					int result = val<5?0:1;
					text::info("Input value = {}. Selecting flow {}",val,result);
					return result;
				},
				flow0,flow1
			)
			| execution::next( [](const string& str)
			{
				return str+" End!";
			})
			
		);
		if ( res.isValid())
		{
			text::info("Result = {}",res.value());
		}else
		{
			try
			{
				std::rethrow_exception(res.error());				
			}
			catch(...)
			{
				::text::error("Some error occured!!");
			}
		}
		
	},0,::tasking::Runnable::killFalse);
}
\endcode
And the output, in a concrete execution, is:
\verbatim
Input value = 3. Selecting flow 0
Result = Flow0 End!
\endverbatim

### Launching flows {#launching_flows}
Flows can also be *launched at same time* (of course, this concept of *same time* depends on the underlying executor capabilities) via \ref mel::execution::flow::launch "flow::launch"
and get a *tuple of ExFuture* as a result, being each position in the tuple the result of the corresponding flow. Below an example of launching three flows,
one of which can throw exception randomly. The function \ref ::mel::execution::flow::on_all "flow::on_all" is used to get the result of all flows as a tuple.
As can be seen, throwing error in any flow is propagated correctly to the final result.
\code {.cpp}
template <class ExecutorType> void _sampleFlowLaunch(ExecutorType ex)
{	
	auto th = ThreadRunnable::create();

	th->fireAndForget([ex] () mutable
	{
		try
		{
			auto finalRes =  mel::tasking::waitForFutureMThread<::mel::core::WaitErrorAsException>(
				execution::launch(ex,[]() noexcept{ return "Starting job!!"s;})
				| execution::parallel_convert(
					[](const string& str)  noexcept
					{
						mel::text::info("parallel_convert task 1, returning void");
					},
					[](const string& str) noexcept
					{
						return str+" Second parallel task"s;
					}
				) 
				| execution::flow::launch( 
					[](auto input) noexcept
					{
						return input | execution::inmediate("hola"s)
						| execution::next( [](const string& s)
							{
								if ( rand()%10 < 5 )
									throw std::runtime_error("parallel:_convert second task. Throwing exception!!");
							}
						); //return void for testing purposes
					},
					[](auto input) noexcept
					{
						return input | execution::inmediate(7.8f);
					}
					,
					[](auto input) noexcept
					{
						return input | execution::next( [](const std::tuple<mel::execution::VoidType,string>& v) noexcept
							{
								return std::get<1>(v).size();
							}
						 );
					}
				)
				| mel::execution::flow::on_all(ex)
			);							
			auto& finalValue = finalRes.value();
			mel::text::info("Final res = (void,{},{})",std::get<1>(finalValue),std::get<2>(finalValue));
		}catch( mel::execution::OnAllException& e)
		{
			try
			{
				rethrow_exception( e.getCause() );
			}catch(std::exception& e)
			{
				mel::text::error("Error {}",e.what());
			}catch(...)
			{
				mel::text::error("OnAllException. unknown error");
			}
		}
		catch(std::exception& e)
		{
			mel::text::error(e.what());
		}catch(...)
		{
			mel::text::error("Unknown error!!!");
		}
		
	},0,::tasking::Runnable::killFalse);
}
\endcode
### Loops {#loops}
It's possible to implement iterations as part of an execution flow. There are two kinds of iterations in flows: *sequential*, implemented with \ref mel::execution::flow::doWhile "flow::doWhile"
and *independent iterations* with \ref mel::execution::flow::loop "flow::loop".

Below an example of using \ref mel::execution::flow::doWhile "doWhile" where a random number is created and shown in console for 4 times, doing a *microthread wait* in each iteration (if used executor allows it)
\code {.cpp}
template <class ExecutorType> void _sampleWhile(ExecutorType ex)
{	
	auto th = ThreadRunnable::create();

	th->fireAndForget([ex] () mutable
	{
		srand(time(NULL));
		int idx = 0;
        auto res = mel::tasking::waitForFutureMThread<::mel::core::WaitErrorNoException>(
				execution::start(ex)
				| execution::doWhile( 
					[]( auto input ) noexcept
					{
						return input | execution::next( []() noexcept -> int
						{
							return rand()%10;
						})
						| execution::next( [](int v ) noexcept
						{
							mel::text::info(" new value = {}",v);
							if constexpr(execution::ExecutorTraits<decltype(ex)>::has_microthreading)
							{
								mel::tasking::Process::wait(2500);
							}
							else
								mel::text::info("Current executor doesn't supports true parallelism, wait not done");
						});
					},
					[idx]() mutable noexcept
					{
						if ( ++idx == 4 )
							return false; //finish while
						else
							return true; //continue iterating
					}
				
			)						
		);
		if ( res.isValid())
		{
			text::info("Finished");
		}else
		{
			try
			{
				std::rethrow_exception(res.error());				
			}
			catch(...)
			{
				::text::error("Some error occured!!");
			}
		}
		
	},0,::tasking::Runnable::killFalse);
}
\endcode 

And now an example of \ref mel::execution::flow::loop "flow::loop" where iterations are independent, and so could be parallelized if executor allows it.
\code{.cpp}
template <class ExecutorType> void _sampleFlowLoop(ExecutorType ex)
{	
	auto th = ThreadRunnable::create();
	th->fireAndForget([ex] () mutable
	{
		srand(time(NULL));
		int idx = 0;
        auto res = mel::tasking::waitForFutureMThread<::mel::core::WaitErrorNoException>(
				execution::start(ex)
				| execution::flow::loop( 0,4,
					[]( int idx, auto input ) noexcept
					{
						return input | execution::next( []() noexcept -> int
						{
							return rand()%10;
						})
						| execution::next( [](int v ) noexcept
						{
							mel::text::info(" new value = {}. Now waiting",v);
							if constexpr(execution::ExecutorTraits<decltype(ex)>::has_microthreading)
							{
								mel::tasking::Process::wait(2500);
							}
							else
								mel::text::info("Current executor doesn't support true parallelism, wait not done");
							mel::text::info(" new value = {}. After wait",v);
						});
					}				
				)
				| execution::next( []{
					mel::text::info(" Flow finished!!");
				})
		);
		if ( res.isValid())
		{
			text::info("Finished");
		}else
		{
			try
			{
				std::rethrow_exception(res.error());				
			}
			catch(...)
			{
				::text::error("Some error occured!!");
			}
		}
		
	},0,::tasking::Runnable::killFalse);
}
\endcode
The fact that independent iterations are used can be seen in the output ,where an iteration doesn't need the previous to be finished:
\verbatim
new value = 9. Now waiting
new value = 1. Now waiting
new value = 3. Now waiting
new value = 3. Now waiting
new value = 9. After wait
new value = 3. After wait
new value = 1. After wait
new value = 3. After wait
\endverbatim

### Flow chart example{#flow_chart}

TODO PONER UN EJEMPLO PITNANDO UN DIAGRAMA DE FLUJO EN IMPLEMENTARLO
*/