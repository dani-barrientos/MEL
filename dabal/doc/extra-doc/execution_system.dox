
/**
\page execution_system Execution System
The goal of this module is to provide a very high level API for task execution in a generic way, such that is not neccesary to know the underlying execution system.
This *problem* it's becoming very important because the need to exploit the modern hardware. As the CPU speed is incrementing very slowly, the improvements in software development come from taking advantage
of the parallel capacities, use of GPU as computational resource, distributed systems...So, it's necessasary to provide new idioms to programmers such that doing this kind of tasks won't be a hell. 

DABAL provides clasical mechanism for concurrent/parallel programming: \ref core::Thread "threads", \ref ::core::CriticalSection "critical sections",...and no so classicals as the microchtread 
system, which is described in another sections. These tools are enoguh for simple tasks. But there are two main problems:
 - The way the user make the code will depend on the used tool: the code won't be the same if using a thread to launch a task or a microthread. Or, even worse, use the GPU or other systems
 - Doing complex task can be hard to express and the programmer will soon get lost in the code.

 For example, let's assume we want to execute a task *t1* in some thread, then, when the task is finished, execute another task *t2* and, when this is finished, execute two parallel tasks *t3* and *t4* in some thread pool.
 With the *basic* tools in dabal, this is not so much hard, but a kind of mess. The code could be:
 \code
  auto th1 = ThreadRunnable::create();

  auto fut = th1->excute<void>([]()
  {
     //...task t1... 
  }); 
  try
  {
    auto res = core::waitForFutureThread(fut); //depending on the concrete situation where this code is running, maybe use some other mechanism as tasking::waitForFutureMThread or ::core::Future::subscribeCallback
    //now execute task t2
    auto fut2 = th1->excute<void>([]()
    {
        //...task t2... 
    }); 
    auto res2 = core::waitForFutureThread(fut2);
    //now execute t3 and t4
    ThreadPool::ThreadPoolOpts opts;      
    ThreadPool myPool(opts);
    ThreadPool::ExecutionOpts exopts;
    auto barrier = myPool.execute<void>(exopts,
        []()
        {
            //..t3..
        },
        []()
        {
            //..t4..
        }
    );
    core::waitForBarrierThread(barrier);
    //......
  }catch(...)
  {
      //...manage error..
  }  
  \endcode
As can be seen, dabal already provides high level tools to facilitate task execution. But, despite of that, it can be hard to manage a complex execution sequence. Think, for example, how to manage error
in any point of the chain. And, of course, think how to resolve the same problem only with plain C++ threads...

Instead, with the execution system, built on top of those functionalities, we could write:

\code
    auto th1 = ThreadRunnable::create(true);	
	execution::Executor<Runnable> exr(th1); //Create executor based on ThreadRunnable
    parallelism::ThreadPool::ThreadPoolOpts opts;
	auto myPool = make_shared<parallelism::ThreadPool>(opts);
	parallelism::ThreadPool::ExecutionOpts exopts;
	execution::Executor<parallelism::ThreadPool> extp(myPool); //create another executor based on ThreadPool
    try
    {
        auto res = tasking::waitForFutureThread(
            execution::launch(ex, []()
            {
                //...task t1...
            })
            | execution::next( []()
            {
                //...task t2...
            })
            | transfer(extp)
            | execution::parallel(
                []()
                {
                    //... taks t3...
                },
                []()
                {
                    //... taks t4...
                }
            )
        );

    }catch(...)
    {

    }
\endcode
As can be seen in the example code, the expresiveness and flexibility of this mechanism is far superior. The used executor can be any executor type, the *only thing* to do 
(of course, it can be difficult) is to implement the neccesary parts of a new execution system when neccesary (for example, an execution system based on GPU processing).
Dabal provides two types of executors, the ones used in this example: an executor based on \ref tasking::Runnable "runnables" and an executor based on \ref ::core::ThreadPool "a thread pool".
Both has microthread capabilities, meaning that the tasks executed in any of then can take advange of cooperative multitasking (see ::Tasking::Process).
Some examples will be provided in the next sections trying to describe al the functionalities with simple cases, and showing all the power of this system.
## Usage samples
The following samples are for educational purposes only. This means that the task acomplished may not make any sense or that aren't dont in the best possible way. The goal
is to show the different functionalities and its power.
All the samples are done without worrying on the underlying executor, and implemented as template functions.
This functions could be used as:
\code
	//create a RunnableExecutor
	auto th = ThreadRunnable::create(true);			
	execution::Executor<Runnable> exr(th);
	exr.setOpts({true,false,false});
	_sampleBasic(exr); //call sample with the RunnableExecutor
	//now create an executor based on a ThreadPool
	parallelism::ThreadPool::ThreadPoolOpts opts;
	auto myPool = make_shared<parallelism::ThreadPool>(opts);
	parallelism::ThreadPool::ExecutionOpts exopts;
	execution::Executor<parallelism::ThreadPool> extp(myPool);
	extp.setOpts({true,true});	
	_sampleBasic(extp); //use same sample with this new executor
	
\endcode
### Basic sample
A simple execution chain. This code consists of three execution steps:
	- first task generating a float, from another float given as argument
	- second task converting this float to string, a passing it to the next step
	- third step launch three *parallel* tasks. This doesn't mean neccesarily that that task will be executed in parallel,
	is just a hint so that the executor will do it in that way if it hast the capacity.
\code
template <class ExecutorType> void _sampleBasic(ExecutorType ex)
{	
	auto th = ThreadRunnable::create();
	th->fireAndForget([ex] () mutable
	{
		auto res = ::tasking::waitForFutureMThread(
			execution::launch(ex,[](float param) noexcept
			{	
				return param+6.f;
			},10.5f)
			| execution::next( [](float& param) noexcept
			{
				return std::to_string(param);
			})
			| execution::parallel( 
				[](string& str)
				{					
					text::info("Parallel 1. {}",str+" hello!");
				},
				[](string& str)
				{
					text::info("Parallel 2. {}",str+" hi!");
				},
				[](string& str)
				{
					text::info("Parallel 2. {}",str+" whats up!");
				}
			)
		);
		if (res.isValid())
		{
			::text::info("Result value = {}",res.value());
		}
	},0,::tasking::Runnable::_killFalse);
}
\endcode
Output will be:
\code
Parallel 1. 16.500000 hello!
Parallel 2. 16.500000 hi!
Parallel 2. 16.500000 whats up!
Result value = 16.500000
\endcode
### Using references
In this example, it's shown how to use references to variables. In order to be able to pass a reference to \ref ::execution::launch "launch" or to \ref ::execution::inmediate "inmediate"
we must use [std::ref](https://en.cppreference.com/w/cpp/utility/functional/ref), because it's not possible to deduce what the user wants only by the type of the parameter.
Also, when a function wants to return a reference to the next function in the chain, it's neccesary to indicate it without auto deduction. So, if using a lambda as in the examples,
you must specify the return type.

\code
template <class ExecutorType> void _sampleReference(ExecutorType ex)
{	
	string str = "Hello";
	auto th = ThreadRunnable::create();
	th->fireAndForget([ex,&str] () mutable
	{
		auto res = ::tasking::waitForFutureMThread(
			execution::launch(ex,[](string& str) noexcept ->string&
			{	
				//First job
				str += " Dani.";
				return str;
			},std::ref(str))
			| execution::next( [](string& str) noexcept -> string&
			{
				//Second job 
				str+= " How are you?";
				return str;
			})
			| execution::next( [](string& str ) noexcept
			{
				//Third job
				str += "Bye!";
				return str;
			})
			| execution::next( [](string& str ) noexcept
			{
				//Fourth job
				str += "See you!";
				return str;
			})
		);
		if (res.isValid())
		{
			::text::info("Result value = {}",res.value());
			::text::info("Original str = {}",str);
		}
	},0,::tasking::Runnable::_killFalse);
}
\endcode
And the output will be:
\code
Result value = Hello Dani. How are you?Bye!See you!
Original str = Hello Dani. How are you?Bye!
\endcode
As can be seen, the original string is modified, but only until third job. because this job doesn't return a reference to the next,that fourth job will
 receive a copy.
Also just as a way to better understanding, the previous code is **functionally equivalent** to this other (redundant parts are removed):
\code
auto res = ::tasking::waitForFutureMThread(
    execution::start(ex)
    | execution::inmediate(std::ref(str))
    | execution::next([](string& str) noexcept ->string&
    {	
        //First job
        str += " Dani.";
        return str;
    })
    | execution::next( [](string& str) noexcept -> string&
    {
        //Second job 
        str+= " How are you?";
        return str;
    })
    | execution::next( [](string& str ) noexcept
    {
        //Third job
        str += "Bye!";
        return str;
    })
    | execution::next( [](string& str ) noexcept
    {
        //Fourth job
        str += "See you!";
        return str;
    })
);
\endcode
Instead of launching a callable intially, the chain of execution is started with a \ref ::execution::start "start", followed by a \ref ::execution::inmediate "inmediate".
Although in this example this doesn't improves anything, can be usefull in other situations.

### Error management
This is a very important part and need to be addressed carefully. When using any of the wait functions (\ref ::tasking::waitForFutureMThread or \ref ::core::waitForFutureThread)
an exception will be thrown if any error occurs while execution that sequence of jobs the program is waiting for. If this wait mechanisms are not used, the returned \ref ::execution::ExFuture
from the execution chain must be checked for error (see \ref ::core::Future_Common::getValue "Future::getValue" and \ref ::core::FutureValue)

Let's see an example code:

\code
template <class ExecutorType> void _sampleError1(ExecutorType ex)
{	
	string str = "Hello";
	auto th = ThreadRunnable::create();
	th->fireAndForget([ex,&str] () mutable
	{
		try
		{
		    auto res = ::tasking::waitForFutureMThread(
                execution::launch(ex,[](string& str) noexcept ->string&
                {	
                    //First job
                    str += " Dani.";
                    return str;
                },std::ref(str))
                | execution::next( [](string& str) -> string&
                {
                    //Second job 
                    str+= " How are you?";
                    throw std::runtime_error("This is an error");
                    //return str;
                })
                | execution::next( [](string& str ) noexcept
                {
                    //Third job. Will never be executed!!!
                    str += "Bye!";
                    return str;
                })
                | execution::next( [](string& str ) noexcept
                {
                    //Fourth job. Will never be executed
                    str += "See you!";
                    return str;
                })
		    );
			::text::info("Result value = {}",res.value());
		}
		catch(core::WaitException& e)
		{
			::text::error("Some error occured!! Code= {}, Reason: {}",e.getCode(),e.what());
		}
		catch(std::exception& e)
		{
			::text::error("Some error occured!! Reason: {}",e.what());
		}
		catch(...)
		{
			::text::error("Some error occured!! Unknwon reason: {}");
		}
		::text::info("Original str = {}",str);
	},0,::tasking::Runnable::_killFalse);
}
\endcode
Output will be:
\code
[error] Some error occured!! Reason: This is an error
[info] Original str = Hello Dani. How are you?
\endcode
In the previous code, and exception is thrown in the second job, so third and fourth jobs won't be executed. The wait is wrapped with a try/catch and the neccesary
exceptions are checked.
Things to take into account:
 - If a job won't throw an exception (you have to be sure) you _shoud mark this function as **noexcept**_. This way, the generated code will be more efficient (mainly in space).
 - Of course, yo can throw any type of object and follow the usual rules for exception management.
 - the *waitForFuture* functions will throw a \ref ::core::WaitException "WaitException" if the wait was unsuccessful, as process killed, timeout,..

But, what if we want to capture the error at some point and continue the chain of jobs? See next example:
\code
template <class ExecutorType> void _sampleError2(ExecutorType ex)
{	
	string str = "Hello";
	auto th = ThreadRunnable::create();
	th->fireAndForget([ex,&str] () mutable
	{
		try
		{
			auto res = ::tasking::waitForFutureMThread(
				execution::launch(ex,[](string& str) noexcept ->string&
				{	
					//First job
					str += " Dani.";
					return str;
				},std::ref(str))
				| execution::next( [](string& str) -> string&
				{
					//Second job 
					str+= " How are you?";
					throw std::runtime_error("This is an error");
					//return str;
				})
				| execution::next( [](string& str ) noexcept
				{
					//Third job. Will never be executed!!!
					str += "Bye!";
					return str;
				})
				| execution::catchError( [](std::exception_ptr err)
				{
					return "Error caught!! ";
				})
				| execution::next( [](string& str ) noexcept
				{
					//Fourth job. 
					str += "See you!";
					return str;
				})
			);
			::text::info("Result value = {}",res.value());
		}
		catch(core::WaitException& e)
		{
			::text::error("Some error occured!! Code= {}, Reason: {}",e.getCode(),e.what());
		}catch(std::exception& e)
		{
			::text::error("Some error occured!! Reason: {}",e.what());
		}
		::text::info("Original str = {}",str);
	},0,::tasking::Runnable::_killFalse);
}
\endcode
And the output will be:
\code
[info] Result value = Error caught!! See you!
[info] Original str = Hello Dani. How are you?
\endcode
Because the error was captured in the job chain, no exception was thrown. The \ref ::execution::catchError "catchError" function gets an exception as parameter
and *must return the same type* as the previous job in the chain (because this type is what that job expects . If no exception was launched *before* the catchError call,
this function will be ignored.

### Changing executor
In this example we will show how to tranfer execution from one executor to another in the same flow. This is acomplished by the function \ref ::execution::transfer "transfer".
It's better seen with an example:
\code
void _sampleTransfer()
{	
	auto th = ThreadRunnable::create();
	execution::Executor<Runnable> exr(th);
	exr.setOpts({true,false,false});
	parallelism::ThreadPool::ThreadPoolOpts opts;
	auto myPool = make_shared<parallelism::ThreadPool>(opts);
	parallelism::ThreadPool::ExecutionOpts exopts;
	execution::Executor<parallelism::ThreadPool> extp(myPool);
	extp.setOpts({true,false});
	th->fireAndForget([exr,extp] () mutable
	{
		
		try
		{
			auto res = ::tasking::waitForFutureMThread(
				execution::start(exr)
				| execution::inmediate("Hello "s)
				| execution::next( [](string& str) noexcept
				{
					//Second job 
					text::info("NEXT: {}",str);
					return str + ". How are you?";
				})
				| execution::transfer(extp)  //now transfer execution to the other executor!!
				| execution::loop(0,10, [](int idx, string& str) noexcept
				{
					text::info("Iteration {}", str + std::to_string(idx));
				})
				| execution::next( [](string& str ) noexcept
				{
					//Fourth job. 
					str += "See you!";
					return str;
				})
			);
			::text::info("Result value = {}",res.value());
		}
		catch(core::WaitException& e)
		{
			::text::error("Some error occured!! Code= {}, Reason: {}",e.getCode(),e.what());
		}catch(std::exception& e)
		{
			::text::error("Some error occured!! Reason: {}",e.what());
		}
	},0,::tasking::Runnable::_killFalse);
}
\endcode
The code consists of two diferent executors, one based on a ThreadRunnable and other based on a ThreadPool. The eecutions start in
the ThreadRunnable executor and just before the loop, execution is transferred to the other. 
### Converging several job flows
usar el on all
PONER EJEMPLOS TIPICOS COMPILABLES Y EJECUTABLES: launch, next, transfer, gestion errores, onall, loop
DOCUMENTAR EL INTERFAZ BIEN EN SU SITIO
contar el tema del "perfect forwarding" y cuando se hacen copias

*/
