
/**
\page execution_system Execution System
The goal of this module is to provide a very high level API for task execution in a generic way, such that is not neccesary to know the underlying execution system.
This *problem* it's becoming very important because the need to exploit the modern hardware. As the CPU speed is incrementing very slowly, the improvements in software development come from taking advantage
of the parallel capacities, use of GPU as computational resource, distributed systems...So, it's necessasary to provide new idioms to programmers such that doing this kind of tasks won't be a hell. 

DABAL provides clasical mechanism for concurrent/parallel programming: \ref core::Thread "threads", \ref ::core::CriticalSection "critical sections",...and no so classicals as the microchtread 
system, which is described in another sections. These tools are enoguh for simple tasks. But there are two main problems:
 - The way the user make the code will depend on the used tool: the code won't be the same if using a thread to launch a task or a microthread. Or, even worse, use the GPU or other systems
 - Doing complex task can be hard to express and the programmer will soon get lost in the code.

 For example, let's assume we want to execute a task *t1* in some thread, then, when the task is finished, execute another task *t2* and, when this is finished, execute two parallel tasks *t3* and *t4* in some thread pool.
 With the *basic* tools in dabal, this is not so much hard, but a kind of mess. The code could be:
 \code
  auto th1 = ThreadRunnable::create();

  auto fut = th1->excute<void>([]()
  {
     //...task t1... 
  }); 
  try
  {
    auto res = core::waitForFutureThread(fut); //depending on the concrete situation where this code is running, maybe use some other mechanism as tasking::waitForFutureMThread or ::core::Future::subscribeCallback
    //now execute task t2
    auto fut2 = th1->excute<void>([]()
    {
        //...task t2... 
    }); 
    auto res2 = core::waitForFutureThread(fut2);
    //now execute t3 and t4
    ThreadPool::ThreadPoolOpts opts;      
    ThreadPool myPool(opts);
    ThreadPool::ExecutionOpts exopts;
    auto barrier = myPool.execute<void>(exopts,
        []()
        {
            //..t3..
        },
        []()
        {
            //..t4..
        }
    );
    core::waitForBarrierThread(barrier);
    //......
  }catch(...)
  {
      //...manage error..
  }  
  \endcode
As can be seen, dabal already provides high level tools to facilitate task execution. But, despite of that, it can be hard to manage a complex execution sequence. Think, for example, how to manage error
in any point of the chain. And, of course, think how to resolve the same problem only with plain C++ threads...

Instead, with the execution system, built on top of those functionalities, we could write:

\code
    auto th1 = ThreadRunnable::create(true);	
	execution::Executor<Runnable> exr(th1); //Create executor based on ThreadRunnable
    parallelism::ThreadPool::ThreadPoolOpts opts;
	auto myPool = make_shared<parallelism::ThreadPool>(opts);
	parallelism::ThreadPool::ExecutionOpts exopts;
	execution::Executor<parallelism::ThreadPool> extp(myPool); //create another executor based on ThreadPool
    try
    {
        auto res = tasking::waitForFutureThread(
            execution::launch(ex, []()
            {
                //...task t1...
            })
            | execution::next( []()
            {
                //...task t2...
            })
            | transfer(extp)
            | execution::parallel(
                []()
                {
                    //... taks t3...
                },
                []()
                {
                    //... taks t4...
                }
            )
        );

    }catch(...)
    {

    }
\endcode
As can be seen in the example code, the expresiveness and flexibility of this mechanism is far superior. The used executor can be any executor type, the *only thing* to do 
(of course, it can be difficult) is to implement the neccesary parts of a new execution system when neccesary (for example, an execution system based on GPU processing).
Dabal provides two types of executors, the ones used in this example: an executor based on \ref tasking::Runnable "runnables" and an executor based on \ref ::core::ThreadPool "a thread pool".
Both has microthread capabilities, meaning that the tasks executed in any of then can take advange of cooperative multitasking (see ::Tasking::Process).
Some examples will be provided in the next sections trying to describe al the functionalities with simple cases, and showing all the power of this system.
## Usage samples
The following samples are for educational purposes only. This means that the task acomplished may not make any sense or that aren't dont in the best possible way. The goal
is to show the different functionalities and its power.
All the samples are done without worrying on the underlying executor, and implemented as template functions.
This functions could be used as:
\code
	//create a RunnableExecutor
	auto th = ThreadRunnable::create(true);			
	execution::Executor<Runnable> exr(th);
	exr.setOpts({true,false,false});
	_sampleBasic(exr); //call sample with the RunnableExecutor
	//now create an executor based on a ThreadPool
	parallelism::ThreadPool::ThreadPoolOpts opts;
	auto myPool = make_shared<parallelism::ThreadPool>(opts);
	parallelism::ThreadPool::ExecutionOpts exopts;
	execution::Executor<parallelism::ThreadPool> extp(myPool);
	extp.setOpts({true,true});	
	_sampleBasic(extp); //use same sample with this new executor
	
\endcode
### Basic sample
A simple execution chain. This code consists of three execution steps:
	- first task generating a float, from another float given as argument
	- second task converting this float to string, a passing it to the next step
	- third step launch three *parallel* tasks. This doesn't mean neccesarily that that task will be executed in parallel,
	is just a hint so that the executor will do it in that way if it hast the capacity.
\code
template <class ExecutorType> void _sampleBasic(ExecutorType ex)
{	
	auto th = ThreadRunnable::create();
	th->fireAndForget([ex] () mutable
	{
		auto res = ::tasking::waitForFutureMThread(
			execution::launch(ex,[](float param) noexcept
			{	
				return param+6.f;
			},10.5f)
			| execution::next( [](float& param) noexcept
			{
				return std::to_string(param);
			})
			| execution::parallel( 
				[](string& str)
				{					
					text::info("Parallel 1. {}",str+" hello!");
				},
				[](string& str)
				{
					text::info("Parallel 2. {}",str+" hi!");
				},
				[](string& str)
				{
					text::info("Parallel 2. {}",str+" whats up!");
				}
			)
		);
		if (res.isValid())
		{
			::text::info("Result value = {}",res.value());
		}
	},0,::tasking::Runnable::_killFalse);
}
\endcode
Outpu will be:
\code
Parallel 1. 16.500000 hello!
Parallel 2. 16.500000 hi!
Parallel 2. 16.500000 whats up!
Result value = 16.500000
\endcode

PONER EJEMPLOS TIPICOS COMPILABLES Y EJECUTABLES: launch, next, transfer, gestion errores, onall
DOCUMENTAR EL INTERFAZ BIEN EN SU SITIO

*/
